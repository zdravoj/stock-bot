{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps\n",
    "\n",
    "1. Get some stock market data\n",
    "2. Save it in csv\n",
    "3. Transform into useable format (keep as price? transform into percent change? per day?)\n",
    "4. Define Neural Network Structure\n",
    "5. Create Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping stock prices in their standard format would allow each entry to serve as ground truth, while a percentage change would be a relative system. To find a stock change from day X to day Y would require recursively multiplying all percentage changes from day Y back to day X.\n",
    "\n",
    "Keeping stock prices in percentage change format would help automatically account for stock splits. Adjusted price already accounts for this, but I don't want to use the adjusted price because I don't understand it enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some stock market data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect the easiest way to do this is with yfinance, though I might look at some other options because yfinance isn't as well maintained as some more professional open source libraries, and it no longer links to a formal yahoo API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polygon.io seems promising, but the free version only has 5 API calls per minute (not sure the extent of data I can grab with a single API call, but it doesn't sound like very much), and I can only access two years of historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll probably stick with yfinance for now. It's the easiest.\n",
    "\n",
    "I've done some work with yfinance and one of the difficulties is that it pulls data into a **multi-index dataframe**. I'll have to **transform it into something tidy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start simple and get a dataset from the DJIA (Dow Jones Industrial Average). It represents a significant portion of the market and it's a good starting point without getting too much in the weeds of big stock data with larger indexes like the S&P 500 or the Wilshire 5000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some obstacles to grapple with are:\n",
    "- **how to handle companies which were bankrupted**. If I don't include these, then the dataset will suffer heavily from survivorship bias.\n",
    "- **how to handle companies which were merged**. A merged company doesn't go out of business (and so is probably still a good investment) but **representing the change in stock price from the merge** might be difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found a list of all companies ever listed on the DJIA, but it's stored in a Wikipedia article where the changes are grouped as companies listed on the DJIA on a certain date. There is some text about which companies are moved / merged, but I'll have to parse the complete list with some programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also the issue of how far to go back for good training data. The DJIA goes back all the way to 1896, but I don't need data back that far for training. Out of convenience, let's have an 80/20 train-test split, where the training set is 40 years, and the testing set is 10 years.\n",
    "\n",
    "I won't pull until today - that seems ridiculous. Let's set the test cutoff to be December 31, 2023. That means the first training observation will be from January 1, 1973. I don't need to pull data from before then, and I don't need to pull companies listed on the DJIA before then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "djia_hist_comps = pd.read_html('https://en.wikipedia.org/wiki/Historical_components_of_the_Dow_Jones_Industrial_Average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Allied-Signal Incorporated</td>\n",
       "      <td>Eastman Kodak Company</td>\n",
       "      <td>Minnesota Mining &amp; Manufacturing Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>Hewlett-Packard Company</td>\n",
       "      <td>Pfizer Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>Hewlett-Packard Company</td>\n",
       "      <td>The Procter &amp; Gamble Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Aluminum Company of America</td>\n",
       "      <td>General Motors Corporation</td>\n",
       "      <td>Philip Morris Companies Inc. ↑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>E.I. du Pont de Nemours &amp; Company</td>\n",
       "      <td>Owens-Illinois, Inc. ↑</td>\n",
       "      <td>Westinghouse Electric Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>General Electric Company</td>\n",
       "      <td>Nike, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Coca-Cola Company</td>\n",
       "      <td>Merck &amp; Co., Inc.</td>\n",
       "      <td>Walgreens Boots Alliance, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>American Express Company</td>\n",
       "      <td>General Motors Corporation</td>\n",
       "      <td>Microsoft Corporation ↑</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0                           1  \\\n",
       "170         Allied-Signal Incorporated       Eastman Kodak Company   \n",
       "104        Bank of America Corporation     Hewlett-Packard Company   \n",
       "83                           AT&T Inc.     Hewlett-Packard Company   \n",
       "191        Aluminum Company of America  General Motors Corporation   \n",
       "238  E.I. du Pont de Nemours & Company      Owens-Illinois, Inc. ↑   \n",
       "40                          3M Company    General Electric Company   \n",
       "17               The Coca-Cola Company           Merck & Co., Inc.   \n",
       "152           American Express Company  General Motors Corporation   \n",
       "\n",
       "                                            2  \n",
       "170  Minnesota Mining & Manufacturing Company  \n",
       "104                               Pfizer Inc.  \n",
       "83               The Procter & Gamble Company  \n",
       "191            Philip Morris Companies Inc. ↑  \n",
       "238         Westinghouse Electric Corporation  \n",
       "40                                 Nike, Inc.  \n",
       "17             Walgreens Boots Alliance, Inc.  \n",
       "152                   Microsoft Corporation ↑  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine all dataframes\n",
    "djia_hist_comps_30_only = djia_hist_comps[1].iloc[:10, :]\n",
    "for df in djia_hist_comps[2:25]:\n",
    "    djia_hist_comps_30_only = pd.concat(\n",
    "        [djia_hist_comps_30_only, df.iloc[:10, :]],\n",
    "        axis='index',\n",
    "        copy=False,\n",
    "        ignore_index=True\n",
    "    )\n",
    "display(djia_hist_comps_30_only.sample(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeps only company name (removes arrows, subscripts, and extraneous info)\n",
    "def remove_name_clutter(company_name):\n",
    "    return re.sub(r\"(?:\\([^\\(\\)]*\\)|\\[[^\\[\\]]*\\])|[^a-zA-Z0-9\\s&]\", '', company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list of company names\n",
    "djia_hist_comps_30_only = djia_hist_comps_30_only.to_numpy().flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only pure company names\n",
    "djia_hist_comps_30_only = [remove_name_clutter(name).strip() for name in djia_hist_comps_30_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distinct company names\n",
    "djia_hist_comps_30_only = set(djia_hist_comps_30_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual removal of explicit duplicates\n",
    "duplicates = [\n",
    "    'UnitedHealth Group Incorporated'\n",
    "]\n",
    "for d in duplicates:\n",
    "    djia_hist_comps_30_only.remove(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3M Company',\n",
       " 'AT&T Corporation',\n",
       " 'AT&T Inc',\n",
       " 'Alcoa Inc',\n",
       " 'Allied Chemical Corporation',\n",
       " 'AlliedSignal Incorporated',\n",
       " 'Altria Group Incorporated',\n",
       " 'Aluminum Company of America']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to list\n",
    "djia_hist_comps_30_only = sorted(list(djia_hist_comps_30_only))\n",
    "djia_hist_comps_30_only[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few companies which are probably indistinguishably duplicates (like AT&T Corporation and AT&T Inc) but because of rebranding or mergers, the companies might be listed differently. I'll need to look into this more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get company tickers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27771ea68735cac1916c104ed3d69e2cb0eb000f6c9d574c6a08d3bbf1e9acce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
